Tareas:


1. Añadir 1 o 2 gráficas más 
2. Darle formato al dashboard:
    * Poner las gráficas en contenedores y desplegar para que se ajusten los anchos

3. Investigar nltk sia y entrenar con corpus de comentarios de yt. Si no se puede:
        Jupyter notebook para preparar varios modelos
            lenguage detection > cleaning process > tokenizer > feature selection > model training
            lenguage detection > cleaning process > tokenizer > model validation > pickle
    
    EL MODELO USADO ACTUALMENTE FUNCIONA MUYYY MAL (no sé si es por la detección de idiomas o por qué)

4. Buscar un corpus y entrenar con él

5. Escribir la memoria

(
6. Inferencia: Determinar número de comentarios mínimo para una buena Inferencia 

7. Muestra aleatoria: La relevancia de un comentario puede depender de la polaridad. La polaridad puede depender de el momento de publicación.
        => Encontrar la manera de tomar una muestra aleatoria de los comentarios
)
